{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPPO Waste Analysis + ML (Colab Ready)\n",
    "\n",
    "This notebook contains the **full workflow** in one place:\n",
    "1. Data loading from Excel.\n",
    "2. Preprocessing and cleaning.\n",
    "3. Descriptive analysis and business KPIs.\n",
    "4. Machine learning model training + comparison for waste prediction (`بالكيلو`).\n",
    "5. Export of outputs for business use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab setup (safe to run in Colab)\n",
    "!pip -q install pandas numpy scikit-learn openpyxl joblib tabulate matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from joblib import dump\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Input file\n",
    "- Upload your Excel file to Colab files panel, then set `DATASET_PATH`.\n",
    "- Example file name from your project: `تقرير يومي عن انتاجيه  الجوده شهر يوليو_cleaned.xlsx`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your file path here\n",
    "DATASET_PATH = \"/content/تقرير يومي عن انتاجيه  الجوده شهر يوليو_cleaned.xlsx\"\n",
    "assert os.path.exists(DATASET_PATH), f\"File not found: {DATASET_PATH}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Preprocessing Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPECTED_COLUMNS = [\n",
    "    \"بالكيلو\", \"الوزن\", \"فرز تاني\", \"محلي\", \"تصدير\", \"السمك\", \"المقاس\",\n",
    "    \"الاوردر\", \"الفني\", \"الجوده\", \"خط الانتاج\", \"الورديه\"\n",
    "]\n",
    "\n",
    "NUMERIC_COLUMNS = [\"بالكيلو\", \"الوزن\", \"فرز تاني\", \"محلي\", \"تصدير\", \"السمك\", \"المقاس\"]\n",
    "TEXT_COLUMNS = [\"الفني\", \"الجوده\", \"خط الانتاج\", \"الورديه\", \"الاوردر\"]\n",
    "\n",
    "LINE_NORMALIZATION = {\n",
    "    \"سليتر 1\": \"سليتر1\",\n",
    "    \"سليتر 2\": \"سليتر2\",\n",
    "    \"تناية 1\": \"تناية1\",\n",
    "    \"تناية 2\": \"تناية2\",\n",
    "    \"تناية 3\": \"تناية3\",\n",
    "    \"تناية 4\": \"تناية4\",\n",
    "    \"تناية1 \": \"تناية1\",\n",
    "}\n",
    "\n",
    "\n",
    "def normalize_whitespace(x):\n",
    "    return \" \".join(str(x).strip().split())\n",
    "\n",
    "\n",
    "def normalize_text_columns(df, columns):\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str).map(normalize_whitespace)\n",
    "            df[col] = df[col].replace({\"nan\": pd.NA, \"\": pd.NA})\n",
    "\n",
    "    if \"خط الانتاج\" in df.columns:\n",
    "        df[\"خط الانتاج\"] = df[\"خط الانتاج\"].replace(LINE_NORMALIZATION)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_and_preprocess_excel(path):\n",
    "    raw = pd.read_excel(path, header=None)\n",
    "\n",
    "    # Same structure handling as your original notebook\n",
    "    work = raw.drop(columns=[0, 1, 9, 15], errors=\"ignore\").copy()\n",
    "    header_row = work.iloc[2].loc[1:]\n",
    "    work.columns = header_row\n",
    "\n",
    "    df = work.drop(index=work.index[0:27]).copy()\n",
    "    available = [c for c in EXPECTED_COLUMNS if c in df.columns]\n",
    "    df = df[available].copy()\n",
    "\n",
    "    for col in NUMERIC_COLUMNS:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    must_have = [c for c in [\"بالكيلو\", \"الفني\", \"خط الانتاج\"] if c in df.columns]\n",
    "    df = df.dropna(subset=must_have)\n",
    "\n",
    "    df = normalize_text_columns(df, TEXT_COLUMNS)\n",
    "\n",
    "    # Remove invalid/unreasonable values\n",
    "    df = df[(df[\"بالكيلو\"] >= 0) & (df[\"بالكيلو\"] < 400)].copy()\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_outliers_iqr_per_line(df, value_col=\"بالكيلو\"):\n",
    "    if value_col not in df.columns or \"خط الانتاج\" not in df.columns:\n",
    "        return df.copy()\n",
    "\n",
    "    parts = []\n",
    "    for _, g in df.groupby(\"خط الانتاج\", dropna=False):\n",
    "        if len(g) < 4:\n",
    "            parts.append(g)\n",
    "            continue\n",
    "        q1 = g[value_col].quantile(0.25)\n",
    "        q3 = g[value_col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        parts.append(g[(g[value_col] >= lower) & (g[value_col] <= upper)])\n",
    "\n",
    "    return pd.concat(parts, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = load_and_preprocess_excel(DATASET_PATH)\n",
    "df_model = remove_outliers_iqr_per_line(df_clean)\n",
    "\n",
    "print(\"Rows after preprocessing:\", len(df_clean))\n",
    "print(\"Rows after per-line IQR filtering:\", len(df_model))\n",
    "df_model.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Descriptive Analysis + Business KPIs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_summary = (\n",
    "    df_model.groupby(\"خط الانتاج\")[\"بالكيلو\"]\n",
    "    .agg(mean=\"mean\", median=\"median\", std=\"std\", count=\"count\", min=\"min\", max=\"max\")\n",
    "    .sort_values(\"mean\", ascending=False)\n",
    ")\n",
    "\n",
    "operator_summary = (\n",
    "    df_model.groupby(\"الفني\")[\"بالكيلو\"]\n",
    "    .agg(avg_waste=\"mean\", median=\"median\", records=\"count\")\n",
    "    .sort_values([\"avg_waste\", \"records\"], ascending=[False, False])\n",
    ")\n",
    "\n",
    "line_operator_summary = (\n",
    "    df_model.groupby([\"خط الانتاج\", \"الفني\"])[\"بالكيلو\"]\n",
    "    .agg(avg_waste=\"mean\", records=\"count\")\n",
    "    .sort_values(\"avg_waste\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"Top 10 high-waste lines\")\n",
    "display(line_summary.head(10))\n",
    "print(\"Top 10 high-waste operators\")\n",
    "display(operator_summary.head(10))\n",
    "print(\"Top 15 high-waste operator-line combos\")\n",
    "display(line_operator_summary.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "line_summary.head(10)[\"mean\"].plot(kind=\"bar\", color=\"#d95f02\")\n",
    "plt.title(\"Top Waste Lines by Mean Waste (kg)\")\n",
    "plt.ylabel(\"Mean Waste (kg)\")\n",
    "plt.xlabel(\"Production Line\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "operator_summary.head(15)[\"avg_waste\"].plot(kind=\"bar\", color=\"#1b9e77\")\n",
    "plt.title(\"Top Operators by Average Waste (kg)\")\n",
    "plt.ylabel(\"Average Waste (kg)\")\n",
    "plt.xlabel(\"Operator\")\n",
    "plt.xticks(rotation=60)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Machine Learning Models to Predict `الجوده` and `الفني`\n",
    "\n",
    "- This section trains multi-output classification models (two targets at once).\n",
    "- Metrics report separate accuracy for each target plus an overall average.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS = [c for c in [\"الجوده\", \"الفني\"] if c in df_model.columns]\n",
    "if len(TARGETS) < 2:\n",
    "    raise ValueError(\"Both targets 'الجوده' and 'الفني' must exist in the dataset.\")\n",
    "\n",
    "CATEGORICAL = [c for c in [\"خط الانتاج\", \"الورديه\", \"الاوردر\"] if c in df_model.columns]\n",
    "NUMERIC = [c for c in [\"بالكيلو\", \"الوزن\", \"فرز تاني\", \"محلي\", \"تصدير\", \"السمك\", \"المقاس\"] if c in df_model.columns]\n",
    "FEATURES = NUMERIC + CATEGORICAL\n",
    "\n",
    "X = df_model[FEATURES].copy()\n",
    "y = df_model[TARGETS].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ]), NUMERIC),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ]), CATEGORICAL),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "base_models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=2000),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=400, random_state=42, n_jobs=-1),\n",
    "    \"ExtraTrees\": ExtraTreesClassifier(n_estimators=500, random_state=42, n_jobs=-1),\n",
    "}\n",
    "\n",
    "results = []\n",
    "fitted = {}\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, base_model in base_models.items():\n",
    "    model = MultiOutputClassifier(base_model)\n",
    "    pipe = Pipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pred = pipe.predict(X_test)\n",
    "\n",
    "    acc_quality = accuracy_score(y_test[TARGETS[0]], pred[:, 0])\n",
    "    acc_technician = accuracy_score(y_test[TARGETS[1]], pred[:, 1])\n",
    "    acc_avg = (acc_quality + acc_technician) / 2\n",
    "\n",
    "    cv_exact_match = cross_val_score(pipe, X_train, y_train, cv=cv, scoring=\"accuracy\")\n",
    "\n",
    "    results.append({\n",
    "        \"model\": name,\n",
    "        \"Accuracy_الجوده\": acc_quality,\n",
    "        \"Accuracy_الفني\": acc_technician,\n",
    "        \"Accuracy_Mean\": acc_avg,\n",
    "        \"CV_ExactMatch_Mean\": cv_exact_match.mean(),\n",
    "        \"CV_ExactMatch_STD\": cv_exact_match.std()\n",
    "    })\n",
    "    fitted[name] = pipe\n",
    "\n",
    "metrics_df = pd.DataFrame(results).sort_values(\"Accuracy_Mean\", ascending=False).reset_index(drop=True)\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = metrics_df.iloc[0][\"model\"]\n",
    "best_model = fitted[best_model_name]\n",
    "print(\"Best model:\", best_model_name)\n",
    "\n",
    "# Feature importance (if supported by first estimator in MultiOutputClassifier)\n",
    "model_obj = best_model.named_steps[\"model\"]\n",
    "if hasattr(model_obj, \"estimators_\") and hasattr(model_obj.estimators_[0], \"feature_importances_\"):\n",
    "    feat_names = best_model.named_steps[\"prep\"].get_feature_names_out()\n",
    "    fi = pd.DataFrame({\n",
    "        \"feature\": feat_names,\n",
    "        \"importance\": model_obj.estimators_[0].feature_importances_\n",
    "    }).sort_values(\"importance\", ascending=False)\n",
    "    display(fi.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Save outputs for business usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"/content/outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "df_model.to_csv(f\"{OUTPUT_DIR}/cleaned_data.csv\", index=False)\n",
    "line_summary.to_csv(f\"{OUTPUT_DIR}/line_summary.csv\")\n",
    "operator_summary.to_csv(f\"{OUTPUT_DIR}/operator_summary.csv\")\n",
    "line_operator_summary.to_csv(f\"{OUTPUT_DIR}/line_operator_summary.csv\")\n",
    "metrics_df.to_csv(f\"{OUTPUT_DIR}/model_metrics.csv\", index=False)\n",
    "dump(best_model, f\"{OUTPUT_DIR}/best_quality_technician_model.joblib\")\n",
    "\n",
    "# Text report\n",
    "with open(f\"{OUTPUT_DIR}/MANAGEMENT_REPORT.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"IPPO Waste Analysis + ML Summary\\n\")\n",
    "    f.write(\"================================\\n\\n\")\n",
    "    f.write(f\"Rows used for modeling: {len(df_model)}\\n\")\n",
    "    f.write(\"Targets: الجوده, الفني\\n\")\n",
    "    f.write(f\"Best model: {best_model_name}\\n\\n\")\n",
    "    f.write(\"Top waste lines:\\n\")\n",
    "    f.write(line_summary.head(5).to_string())\n",
    "    f.write(\"\\n\\nTop waste operators:\\n\")\n",
    "    f.write(operator_summary.head(10).to_string())\n",
    "    f.write(\"\\n\\nModel metrics:\\n\")\n",
    "    f.write(metrics_df.to_string(index=False))\n",
    "\n",
    "print(\"Saved outputs in:\", OUTPUT_DIR)\n",
    "print(sorted(os.listdir(OUTPUT_DIR)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Business recommendations\n",
    "- Use the saved model monthly to forecast expected `الجوده` assignment and responsible `الفني`.\n",
    "- Monitor low-accuracy cases to identify unstable shifts, lines, or orders needing process standardization.\n",
    "- Use target-specific accuracy (`Accuracy_الجوده`, `Accuracy_الفني`) to decide where to improve data quality.\n",
    "- Track KPI trends together with model accuracy metrics every month.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}